{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hamletbot",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mz5b4sJZJuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob\n",
        "import re\n",
        "import random, time, tweepy\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afY4KNEbeR63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6abfe26c-7267-4186-97d4-d271c37ac031"
      },
      "source": [
        "text = \"sample_data/hamlet.txt\"\n",
        "print(\"Hamlet Character List: HAMLET, CLAUDIUS, GHOST, GERTRUDE, KING, QUEEN, \\nPOLONIUS, LAERTES, OPHELIA, HORATIO, FORTINBRAS, VOLTEMAND, CORNELIUS, \\nROSENCRANTZ, GUILDENSTERN, MARCELLUS, BARNARDO, FRANCISCO, OSRIC, REYNALDO\")\n",
        "play_character = input(\"Choose a Hamlet Character: \")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hamlet Character List: HAMLET, CLAUDIUS, GHOST, GERTRUDE, KING, QUEEN, \n",
            "POLONIUS, LAERTES, OPHELIA, HORATIO, FORTINBRAS, VOLTEMAND, CORNELIUS, \n",
            "ROSENCRANTZ, GUILDENSTERN, MARCELLUS, BARNARDO, FRANCISCO, OSRIC, REYNALDO\n",
            "Choose a Hamlet Character: Ophelia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mo9p-WJ-aAN",
        "colab_type": "code",
        "outputId": "41766caa-24cb-4c0a-b78e-7185322c6750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "text = open(text).read() #entire text\n",
        "lines = text.split('\\n\\n') #split text by separate speech\n",
        "c_lines = \"\" #specific character lines\n",
        "\n",
        "#sentiment/speech analysis\n",
        "c_polarity = [] \n",
        "c_subjectivity = []\n",
        "count=0 #number of times the character speaks\n",
        "min_speech = None\n",
        "max_speech = None\n",
        "\n",
        "for i in lines: #going through each speech\n",
        "  if i.find(play_character.upper()+\".\")==0:\n",
        "    if min_speech is None:\n",
        "      min_speech = i\n",
        "      max_speech = i\n",
        "    elif len(i)<len(min_speech):\n",
        "      min_speech = i\n",
        "    elif len(i)>len(max_speech):\n",
        "      max_speech = i\n",
        "    c_polarity.append(TextBlob(i[7:]).sentiment.polarity)\n",
        "    c_subjectivity.append(TextBlob(i[7:]).sentiment.subjectivity)\n",
        "    c_lines+=i[7:]\n",
        "    count+=1\n",
        "words = text.split()\n",
        "\n",
        "#distant reading analysis\n",
        "print(\"Within the play, \" + play_character + \" speaks \" + str(count) + \" times.\")\n",
        "print(\"In total, \" + play_character + \" speaks \"+ str(len(c_lines.split()))+\" words.\")\n",
        "print(\"On average, \" + play_character + \" will speak for \"+ str(len(c_lines.split())//count) + \" words without stopping.\")\n",
        "print(\"\")\n",
        "print( play_character + \"'s shortest speech is \"+str(len(min_speech.split())-1)+\" words long\")\n",
        "print(min_speech)\n",
        "print(\"\")\n",
        "print(play_character + \"'s longest speech is \"+str(len(max_speech.split())-1)+\" words long\")\n",
        "print(max_speech)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Within the play, Ophelia speaks 58 times.\n",
            "In total, Ophelia speaks 1088 words.\n",
            "On average, Ophelia will speak for 18 words without stopping.\n",
            "\n",
            "Ophelia's shortest speech is 2 words long\n",
            "OPHELIA. My lord?\n",
            "\n",
            "Ophelia's longest speech is 124 words long\n",
            "OPHELIA. He took me by the wrist and held me hard; Then goes he to the\n",
            "length of all his arm; And with his other hand thus o’er his brow, He\n",
            "falls to such perusal of my face As he would draw it. Long stay’d he\n",
            "so, At last,—a little shaking of mine arm, And thrice his head thus\n",
            "waving up and down, He rais’d a sigh so piteous and profound As it did\n",
            "seem to shatter all his bulk And end his being. That done, he lets me\n",
            "go, And with his head over his shoulder turn’d He seem’d to find his\n",
            "way without his eyes, For out o’ doors he went without their help, And\n",
            "to the last bended their light on me.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbv0rIKHULUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "acc92776-033d-4541-ff9f-3d742cc56583"
      },
      "source": [
        "c_polarity.sort()\n",
        "print(\"The average polarity of \"+play_character+\"'s speech is \" + str(sum(c_polarity)/len(c_polarity)))\n",
        "print(\"The median polarity of \"+play_character+\"'s speech is \" + str(c_polarity[len(c_polarity)//2]))\n",
        "sns.boxplot(y=c_polarity)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average polarity of Ophelia's speech is 0.11352263446885781\n",
            "The median polarity of Ophelia's speech is 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f98b4e89358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhDtBieKZqvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "4f4ff954-fcad-417a-febf-796e8ebd4433"
      },
      "source": [
        "c_subjectivity.sort()\n",
        "print(\"The average subjectivity of \"+play_character+\"'s speech is \" + str(sum(c_subjectivity)/len(c_subjectivity)))\n",
        "print(\"The median subjectivity of \"+play_character+\"'s speech is \" + str(c_subjectivity[len(c_subjectivity)//2]))\n",
        "sns.boxplot(y=c_subjectivity, palette=[\"g\"])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average subjectivity of Ophelia's speech is 0.3079938380205211\n",
            "The median subjectivity of Ophelia's speech is 0.3666666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f98b4e89470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBVvjU82O0IQ",
        "colab_type": "code",
        "outputId": "343f7143-8ba1-4639-9a33-afc180158de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "start_words =  re.findall('([A-Z][a-z]{0,})', c_lines)\n",
        "print(\"There are \"+str(len(set(start_words)))+\" different start words.\")\n",
        "common_start_words = set([x for x in start_words if start_words.count(x) > 1])\n",
        "print(str(len(common_start_words))+\" start words occur more than once.\")\n",
        "list(common_start_words)[:10]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 83 different start words.\n",
            "35 start words occur more than once.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sings', 'Do', 'Tis', 'Good', 'You', 'O', 'Ay', 'How', 'The', 'No']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeX0iLfi_ZA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ngrams_for_sequence(n, seq):\n",
        "    return [tuple(seq[i:i+n]) for i in range(len(seq)-n+1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqON4218_w0A",
        "colab_type": "code",
        "outputId": "9089f9ea-8a48-46ff-8c1c-6e8879ae5882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "hamlet_word_5grams = ngrams_for_sequence(5, open(\"sample_data/hamlet.txt\").read().split())\n",
        "hamlet_word_5grams[:10]"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SCENE', 'I.', 'Elsinore.', 'A', 'platform'),\n",
              " ('I.', 'Elsinore.', 'A', 'platform', 'before'),\n",
              " ('Elsinore.', 'A', 'platform', 'before', 'the'),\n",
              " ('A', 'platform', 'before', 'the', 'Castle.'),\n",
              " ('platform', 'before', 'the', 'Castle.', 'Enter'),\n",
              " ('before', 'the', 'Castle.', 'Enter', 'Francisco'),\n",
              " ('the', 'Castle.', 'Enter', 'Francisco', 'and'),\n",
              " ('Castle.', 'Enter', 'Francisco', 'and', 'Barnardo,'),\n",
              " ('Enter', 'Francisco', 'and', 'Barnardo,', 'two'),\n",
              " ('Francisco', 'and', 'Barnardo,', 'two', 'sentinels.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeZNhnj3AHU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_to_model(model, n, seq):\n",
        "    # make a copy of seq and append None to the end\n",
        "    seq = list(seq[:]) + [None]\n",
        "    for i in range(len(seq)-n):\n",
        "        # tuple because we're using it as a dict key!\n",
        "        gram = tuple(seq[i:i+n])\n",
        "        next_item = seq[i+n]            \n",
        "        if gram not in model:\n",
        "            model[gram] = []\n",
        "        model[gram].append(next_item)\n",
        "\n",
        "def markov_model(n, seq):\n",
        "    model = {}\n",
        "    add_to_model(model, n, seq)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrWhc6LSAKMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c_markov_model = markov_model(2, c_lines.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOamotPtAxZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "def gen_from_model(n, model, start=None, max_gen=100):\n",
        "    if start is None:\n",
        "        start = random.choice(list([i for i in model.keys() if i[0] in common_start_words])) #choose a common start phrases\n",
        "    output = list(start)\n",
        "    for i in range(max_gen):\n",
        "        start = tuple(output[-n:])\n",
        "        next_item = random.choice(model[start])\n",
        "        if next_item is None:\n",
        "            break\n",
        "        else:\n",
        "            output.append(next_item)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm_dSV3cVNbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imitate_character():\n",
        "  generated_words = gen_from_model(2, c_markov_model, None, 18) #bigram approach, with a total of 18 words max\n",
        "  strange = ' '.join(generated_words)\n",
        "  #find the last punctuation in the text\n",
        "  period = strange.rfind('.')\n",
        "  exclamation = strange.rfind('!')\n",
        "  question = strange.rfind('?')\n",
        "  end = max(period, max(exclamation,question))\n",
        "  return strange[:end+1] #return all the complete sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7-jaw4BSXBL",
        "colab_type": "code",
        "outputId": "fde4a29f-19d1-4604-ec89-48dd965b67a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "source": [
        "CONSUMER_KEY = 'PLACE YOUR OWN CONSUMER KEY HERE'\n",
        "CONSUMER_SECRET = 'PLACE YOUR OWN CONSUMER SECRET HERE'\n",
        "ACCESS_KEY = 'PLACE YOUR OWN ACCESS KEY HERE'\n",
        "ACCESS_SECRET = 'PLACE YOUR OWN ACCESS SECRET HERE'\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
        "api = tweepy.API(auth)\n",
        "i = 1\n",
        "possible_tweets=[]\n",
        "while i<=5: #give the user 5 options to tweet out\n",
        "  postthis = imitate_character()\n",
        "  if len(postthis)>0 and len(postthis) <= 140:\n",
        "    print(str(i)+\": \"+postthis)\n",
        "    print(TextBlob(postthis).sentiment)\n",
        "    print(\"\")\n",
        "    possible_tweets.append(postthis)\n",
        "    i+=1\n",
        "print(\"Type 6 to cancel\")\n",
        "print(\"\")\n",
        "choice = int(input(\"Choose one of these to post(#): \") )\n",
        "if choice>0 and choice<6: #tweet if they choose a valid number\n",
        "  api.update_status(status=possible_tweets[choice-1])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: The glass of fashion and the mould of form, Th’observ’d of all observers, quite, quite down!\n",
            "Sentiment(polarity=-0.19444444444444448, subjectivity=0.2888888888888889)\n",
            "\n",
            "2: Good my lord, How does your honour for this many a day?. My lord, I have been so affrighted..\n",
            "Sentiment(polarity=0.6, subjectivity=0.55)\n",
            "\n",
            "3: By Gis and by Saint Charity, Alack, and fie for shame!\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "\n",
            "4: What means this, my lord?. You are keen, my lord, With almost all the holy vows of heaven..\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "\n",
            "5: My brother shall know of it. And so I thank you for your good counsel. Come, my coach!\n",
            "Sentiment(polarity=0.875, subjectivity=0.6000000000000001)\n",
            "\n",
            "Type 6 to cancel\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-ade860aa6e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type 6 to cancel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Choose one of these to post(#): \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mchoice\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#tweet if they choose a valid number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpossible_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}